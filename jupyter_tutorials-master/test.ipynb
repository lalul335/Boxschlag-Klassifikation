{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:06:52.900902100Z",
     "start_time": "2024-06-07T09:06:52.886890500Z"
    }
   },
   "outputs": [],
   "source": [
    "#import neccessary modules\n",
    "# uuid is used to generate unique identifiers\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# helper functions\n",
    "from timeseries_helpers import datasetstorer\n",
    "from timeseries_helpers import dataset_importer\n",
    "from timeseries_helpers import database_importer\n",
    "from timeseries_helpers import standardizer\n",
    "from data_preprocessing import extract_accelerometer_data, csv_to_dataset_list\n",
    "from timeseries_helpers import classificationHelpers\n",
    "import data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:06:55.280754200Z",
     "start_time": "2024-06-07T09:06:52.901902400Z"
    }
   },
   "id": "efb5e656ab8a9189"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 216456 entries, 0 to 216461\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   timestamp  216456 non-null  float64\n",
      " 1   x          216456 non-null  float64\n",
      " 2   y          216456 non-null  float64\n",
      " 3   z          216456 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 8.3 MB\n",
      "Data imported without any errors!\n",
      " ##### Information: ####\n",
      " Imported datasets: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "\n",
    "data_2 = pd.read_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Kinnhacken.csv')\n",
    "data_1 = pd.read_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gerade.csv')\n",
    "data_3 = pd.read_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Kopfhacken.csv')\n",
    "data_4 = pd.read_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gemischt_01.csv')\n",
    "data_5 = pd.read_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gemischt_02.csv')\n",
    "\n",
    "# List of CSV file paths\n",
    "csv_files = glob.glob(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\*.csv')\n",
    "\n",
    "# List to store each CSV file as a DataFrame\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV file paths\n",
    "for csv_file in csv_files:\n",
    "    # Read CSV file into DataFrame and append to list\n",
    "    dfs.append(pd.read_csv(csv_file))\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\jupyter_tutorials-master\\Merged_df.csv', index=False)\n",
    "\n",
    "ds = csv_to_dataset_list(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\jupyter_tutorials-master\\Merged_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:10.804242200Z",
     "start_time": "2024-06-07T09:06:55.285716400Z"
    }
   },
   "id": "bb4dd20526582585"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'\\Users\\raouldoublan\\Documents\\GitHub\\Boxschlag-Klassifikation'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Now you can save your file in the 'directory'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:10.820199500Z",
     "start_time": "2024-06-07T09:07:10.805239500Z"
    }
   },
   "id": "14db66f3d77fb744"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = extract_accelerometer_data(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gerade.csv')\n",
    "\n",
    "def csv_to_json(file_path, ds = []):\n",
    "    # Read the CSV file and morph it into a indexed Dictionary\n",
    "    data = extract_accelerometer_data(file_path)\n",
    "    \n",
    "    # create raws\n",
    "    raws = []\n",
    "    for idx, row in data.iterrows():\n",
    "        raw = {'_id' : idx, 'timestamp' : row['timestamp'], 'x' : row['x'], 'y' : row['y'], 'z' : row['z']}\n",
    "        raws.append(raw)\n",
    "\n",
    "        \n",
    "    # insert raws into dataset\n",
    "    dataset = {'raws': raws, 'label': 0, 'count': len(data)}\n",
    "    \n",
    "    # append dataset to dataset list\n",
    "    ds.append(dataset)\n",
    "    \n",
    "    return ds\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:11.198332300Z",
     "start_time": "2024-06-07T09:07:10.824189100Z"
    }
   },
   "id": "cd5e84ba9ef0b4ab"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.021240234375\n"
     ]
    }
   ],
   "source": [
    "data = extract_accelerometer_data(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gerade.csv')\n",
    "\n",
    "print(data.iloc[1]['x'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:11.547137200Z",
     "start_time": "2024-06-07T09:07:11.200326900Z"
    }
   },
   "id": "73ddb1a047acdb62"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = csv_to_json(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gerade.csv')\n",
    "ds = extract_accelerometer_data(r'C:\\Users\\Raoul\\Documents\\GitHub\\Boxschlag-Klassifikation\\data\\Max_Gerade.csv')\n",
    "\n",
    "#print(ds)\n",
    "print(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:13.579743900Z",
     "start_time": "2024-06-07T09:07:11.548134900Z"
    }
   },
   "id": "2dd7beaff3c143b2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## period length in ms\n",
    "periodLengthMS = 1000\n",
    "\n",
    "## sample rate in Âµs\n",
    "sampleRateUS = 10000\n",
    "\n",
    "## test/train ratio\n",
    "trainDataRatio = 0.7\n",
    "trainDataAbs = 100*trainDataRatio\n",
    "\n",
    "## Json dataset path\n",
    "jsonDSpath = '/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:13.585728300Z",
     "start_time": "2024-06-07T09:07:13.580741200Z"
    }
   },
   "id": "3a22b59594435e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#with open('/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json', 'r') as f:\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#    jsnDataset = json.load(f)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m tweets \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m file:\n\u001B[0;32m      7\u001B[0m         tweets\u001B[38;5;241m.\u001B[39mappend(json\u001B[38;5;241m.\u001B[39mloads(line))\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Boxschlag-Klassifikation\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[1;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json'"
     ]
    }
   ],
   "source": [
    "#with open('/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json', 'r') as f:\n",
    "#    jsnDataset = json.load(f)\n",
    "\n",
    "tweets = []\n",
    "with open('/Users/raouldoublan/Documents/GitHub/Boxschlag-Klassifikation/data/Merged_Data.json', 'r') as file:\n",
    "    for line in file:\n",
    "        tweets.append(json.loads(line))\n",
    "\n",
    "dl = database_importer.jsonData_to_dataset_in_timedifference_us(tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:14.355267100Z",
     "start_time": "2024-06-07T09:07:13.583734400Z"
    }
   },
   "id": "fcd6ae163f3cc7b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "buff = classificationHelpers.prepareDataset(jsonDSpath, periodLengthMS, sampleRateUS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T09:07:14.358235800Z"
    }
   },
   "id": "ea71aa18a8417903"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# converts the given list of dataframes to one dataframe\n",
    "df_list = []\n",
    "for idx,e in enumerate(ds):\n",
    "    df = e.assign(punch_id=idx)\n",
    "    df['label'] = 0\n",
    "    df_list.append(df)\n",
    "df_res = pd.concat(df_list)\n",
    "df_new = df_res.reset_index(drop=True)\n",
    "df_new = df_new.rename(index=str, columns={\"accelerometerAccelerationX(G)\": \"a_x\", \"accelerometerAccelerationY(G)\": \"a_y\", \"accelerometerAccelerationZ(G)\":\"a_z\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T09:07:14.362225700Z",
     "start_time": "2024-06-07T09:07:14.360230800Z"
    }
   },
   "id": "7bb179f9bb99a2ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T09:07:14.363222400Z"
    }
   },
   "id": "fbe87879e7d2fd10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_new.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T09:07:14.366214Z"
    }
   },
   "id": "854486acebc65ebd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T09:07:14.367211500Z"
    }
   },
   "id": "ca64bf630101c9c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
